\documentclass[10pt]{article}
\usepackage{fullpage,graphicx,psfrag,amsmath,amsfonts,verbatim}
\usepackage[small,bf]{caption}
\usepackage{enumitem}


\newcommand{\ones}{\mathbf 1}
\newcommand{\reals}{{\mbox{\bf R}}}
\newcommand{\integers}{{\mbox{\bf Z}}}
\newcommand{\symm}{{\mbox{\bf S}}}  % symmetric matrices

\newcommand{\nullspace}{{\mathcal N}}
\newcommand{\range}{{\mathcal R}}
\newcommand{\Rank}{\mathop{\bf Rank}}
\newcommand{\Tr}{\mathop{\bf Tr}}
\newcommand{\diag}{\mathop{\bf diag}}
\newcommand{\card}{\mathop{\bf card}}
\newcommand{\rank}{\mathop{\bf rank}}
\newcommand{\conv}{\mathop{\bf conv}}
\newcommand{\zero}{\mathop{\bf 0}}
\newcommand{\prox}{\mathbf{prox}}

\newcommand{\Expect}{\mathop{\bf E{}}}
\newcommand{\Prob}{\mathop{\bf Prob}}
\newcommand{\Co}{{\mathop {\bf Co}}} % convex hull
\newcommand{\dist}{\mathop{\bf dist{}}}
\newcommand{\argmin}{\mathop{\rm argmin}}
\newcommand{\argmax}{\mathop{\rm argmax}}
\newcommand{\epi}{\mathop{\bf epi}} % epigraph
\newcommand{\Vol}{\mathop{\bf vol}}
\newcommand{\dom}{\mathop{\bf dom}} % domain
\newcommand{\intr}{\mathop{\bf int}}
\newcommand{\sign}{\mathop{\bf sign}}

\newcommand{\cf}{{\it cf.}}
\newcommand{\eg}{{\it e.g.}}
\newcommand{\ie}{{\it i.e.}}
\newcommand{\etc}{{\it etc.}}
\bibliographystyle{alpha}

\title{Homework 4 for MATH 312}
\author{Ashok M. Rao}

\begin{document}
\maketitle
\pagenumbering{gobble}


\paragraph{Matrix substitution}
The algorithm characterizing substitution in the case of $A = LU$ is essentially solving for $y$, where $Ly = b$, and recovering the solution to $Ax = b$ as $Ux = y$.  Performing this first substitution for the given matrices yields $y = (1, 0, 1, 0)$ and then back substituting yields $x = (2, -1, 1, 0)$. 
\paragraph{(Strang 3.1.17)}
The set of invertible matrices is given by $\mathcal{A} = \left\{A\mid A, B\in \reals^{n\times n}\text{ and } AB = I \text{ and } BA = I_n\right\}$. The matrices $\mathcal{A}$ trivially do not form a subspace as the zero matrix $\zero$ clearly cannot be inverted. The set of singular matrices is given by $\mathcal{A}^c$, the absolute complement of $\mathcal{A}$ in the space of $n$-dimensional square matrices $\reals^{n\times n}$. Clearly $\mathcal{A}^c$ is not a subspace either. Let $\diag{x}\in\reals^{n\times n}$ be the matrix formed with the vector $x$ and all zeros otherwise. Then clearly $\diag{(0,1)}$ and $\diag{(1,0)}\in\mathcal{A}^c$ and just as clearly $\diag{(0,1)} + \diag{(1,0)} \in \mathcal{A}$. Thus $\mathcal{A}^c$ cannot be a subspace given that it isn't closed under addition. 

\paragraph{Column space of invertible matrices}
The invertibility of $A\in\reals^{n\times n}$ requires that $Ax=0$ admit only the trivial solution $x=\zero$. Otherwise, $A^{-1}Ax = Ix$ would contradict the fact that $A\zero=\zero$ for any $A$. Thus $N(A)$ has dimension zero and consists only of the trivially zero vector.  It follows that the matrix has column space of dimension $n$, \eg it is full rank and equivalently $C(A) = \reals^n$. 

\paragraph{(Strang 3.2.1)}
$A$ and $B$ reduce to their triangular echelon forms respectively by letting $A_2\leftarrow A_2-A_1$, $A_3\leftarrow A_3-A_2$ and $B_3 \leftarrow B_3 - 2B_2$ (and dividing by the pivots)
\[A=
\begin{bmatrix}
1& 2& 2& 4& 6\\
1& 2& 3& 6& 9\\
0& 0& 1& 2& 3	
\end{bmatrix}\rightarrow
\begin{bmatrix}
1& 2& 2& 4& 6\\
0& 0& 1& 2& 3\\
0& 0& 0& 0& 0	
\end{bmatrix},\quad
B = \begin{bmatrix}
	2& 4& 2\\
	0& 4& 4\\
	0& 8& 8
\end{bmatrix}\rightarrow
\begin{bmatrix}
	1& 2& 1\\
	0& 1& 1\\
	0& 0& 0
\end{bmatrix}\]
Thus $A$ is pivoted by $x_1, x_3$ and has $x_2, x_4, x_5$ as free variables. $B$ is pivoted by $x_1, x_2$ and has $x_3$ as a free variable.

\paragraph{(Strang 3.2.20)} The dimension of the nullspace is given by $n-r$ so both $N(A)$ and $C(A)$ would have unit dimension in the given case. The kernel must be a line so without loss of generality $N(A) = \left\{(0, x)\mid x\in\reals\right\}$. To satisfy the definition of $N(A)$, let the first column of $A$ be a line, which for simplicity we will take in the direction of a basis vector, and the second column be the zero vector, \eg 
\[Ax = \begin{bmatrix}0& 0\\a& 0\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}=a\begin{bmatrix}0\\x\end{bmatrix},\quad
Az=\begin{bmatrix}0& 0\\a& 0\end{bmatrix}\begin{bmatrix}0\\y\end{bmatrix} = \begin{bmatrix}0\\0\end{bmatrix}\]
The column space of $A$ is the line traced by $Ax$ and the null space is another line that takes $A$ to the zero vector.

\paragraph{(Strang 3.2.53)}
Write $A$ and $B$ as 
\[A =
\begin{bmatrix}
	1& 1& 0\\
	1& 1& 0\\
	1& 1& 0
\end{bmatrix}+
\begin{bmatrix}
	0& 0& 0\\
	0& 0& 4\\
	0& 0& 8
\end{bmatrix},\quad 
B = \begin{bmatrix}2&0\\2& 0\end{bmatrix} + 
\begin{bmatrix}0&2\\0& 3\end{bmatrix}\]
Each of the combined matrices are trivially rank one, and solve the required by simple matrix addition.
\end{document}